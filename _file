import { HfInference } from "@huggingface/inference";

const inference = new HfInference("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");

for await (const chunk of inference.chatCompletionStream({
  model: "microsoft/Phi-3-mini-4k-instruct",
  messages: [{ role: "user", content: "What is the capital of France?" }],
  temperature: 0.5,
  max_tokens: 1000,
  top_p: 0.7,
})) {
  process.stdout.write(chunk.choices[0]?.delta?.content || "");
}
